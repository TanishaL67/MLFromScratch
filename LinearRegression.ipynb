{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2MfnUxTtn3mvUOE2xAKZe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanishaL67/MLFromScratch/blob/main/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression\n",
        "\n",
        "\n",
        "Linear Regression is the simplest model. A linear model makes a prediction by simply computing a weighted sum of the input features, plus a constant called the bias term also called the intercept term.\n",
        "\n",
        "Here is the Linear Regression model prediction equation:\n",
        "$$\n",
        "\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_n x_n\n",
        "$$\n",
        "\n",
        "We will train the model, which means setting the parameters such that the model best fits the training set. To measure how well the model fits the training set we will use the Root Mean square error (RMSE) and to train the model we will need to find the value of parameters that will minimize the RMSE."
      ],
      "metadata": {
        "id": "ZhToSfZjl2c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we will use the pandas and numpy library to code the linear regression model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "\n",
        "# Load the California Housing dataset\n",
        "california = fetch_california_housing()\n",
        "\n",
        "# Convert to a DataFrame for easy manipulation\n",
        "df = pd.DataFrame(california.data, columns=california.feature_names)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkGBRk0vmD8Q",
        "outputId": "2cbd4e25-375a-4690-a0cb-c2d43e369730"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
            "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
            "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
            "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
            "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
            "\n",
            "   Longitude  \n",
            "0    -122.23  \n",
            "1    -122.22  \n",
            "2    -122.24  \n",
            "3    -122.25  \n",
            "4    -122.25  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normal Equation\n",
        "\n",
        "To find the value of parameters that minimizes the cost function, there is a closed form solution - a mathematical equation that gives the result directly. This is called the Normal Equation.\n",
        "\n",
        "Normal equation is the dot product of inverse of dot product X transpose and X with X transpose and y.\n",
        "\n"
      ],
      "metadata": {
        "id": "O9vCGYFVlp3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will start coding the linear regression model from scratch.\n",
        "class LinearRegression:\n",
        "  def __init__(self):\n",
        "    #we start with initialising the coefficients and intercepts\n",
        "    self.coefficients = None\n",
        "    self.intercept = None\n",
        "\n",
        "  def feature_scaling(self, X):\n",
        "    # Apply Standard Scaling to features (Z-score scaling)\n",
        "    self.mean = np.mean(X, axis=0)\n",
        "    self.std = np.std(X, axis=0)\n",
        "    X_scaled = (X - self.mean) / self.std\n",
        "    return X_scaled\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # Scale features first\n",
        "    X = self.feature_scaling(X)\n",
        "    # add a column of ones for the intercept (bias term)\n",
        "    ones = np.ones((len(X), 1))\n",
        "    X = np.concatenate((ones, X), axis=1)\n",
        "    # We need to calculate the normal equation\n",
        "    XT = X.T\n",
        "    XTX = XT.dot(X)\n",
        "    XTX_inv = np.linalg.inv(XTX) #\n",
        "    XTy = XT.dot(y)\n",
        "    self.coefficients = XTX_inv.dot(XTy)\n",
        "\n",
        "  def predict(self, X):\n",
        "    #add the columns of ones to match the structure used in fitting the model\n",
        "    X = (X - self.mean) / self.std\n",
        "    ones = np.ones((len(X), 1))\n",
        "    X = np.concatenate((ones, X), axis=1)\n",
        "    return X.dot(self.coefficients)\n",
        "\n",
        "  def Rsquared(self, X, y):\n",
        "    ypred = self.predict(X)\n",
        "    ss_total = np.sum((y - np.mean(y))**2) #total sum of squares\n",
        "    ss_residual = np.sum((y - ypred)**2) #residual sum of squares\n",
        "    r2 = 1 - (ss_residual / ss_total) #R-squared formula\n",
        "    return r2\n"
      ],
      "metadata": {
        "id": "h-EzTU3NrZpS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['MedHouseVal'] = california.target  # Target variable\n",
        "X = df.drop(columns=['MedHouseVal']).values  # Features as numpy array\n",
        "y = df['MedHouseVal'].values  # Target as numpy array\n",
        "\n",
        "#test train split(80-20 split)\n",
        "def train_test_split(X, y, test_size=0.3, random_state=None):\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    split_index = int((1 - test_size) * len(X))\n",
        "\n",
        "    X_train, X_test = X[indices[:split_index]], X[indices[split_index:]]\n",
        "    y_train, y_test = y[indices[:split_index]], y[indices[split_index:]]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Perform the manual train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Output the shapes to confirm the split\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMv23uQxvng1",
        "outputId": "9662e3e8-8ce2-4ff6-d417-695dbc7355f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (16512, 8) (16512,)\n",
            "Testing set shape: (4128, 8) (4128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will now initialize and fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "JZagEJy2xn6_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypored = model.predict(X_test)\n",
        "print(ypored)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS5cAXJrx2Ng",
        "outputId": "dde5b91a-abca-4ab6-ab60-14312f87f2cf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.96867243 1.56633224 1.81157253 ... 2.03410525 2.83710153 2.2572115 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's calculate the R-'squared value for the given data points\n",
        "r2 = model.Rsquared(X_test, y_test)\n",
        "print(r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlv6xuAhx8Sk",
        "outputId": "8e562631-7d15-474c-b603-78c856dac15d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5875292022460028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CQrKQbCnvmsj"
      }
    }
  ]
}